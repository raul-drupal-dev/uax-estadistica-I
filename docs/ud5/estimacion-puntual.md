---
title: "UD5 â€” EstimaciÃ³n puntual y propiedades de estimadores"
slug: "ud5-estimacion-puntual"
date: "2026-01-14"
authors: ["Profesor Ejemplo", "Raul Jimenez"]
tags: ["ud5", "inferencias", "estimacion", "puntual", "ecm", "sesgo", "consistencia"]
difficulty: "intermedio"
type: "definicion"
prerequisitos: ["ud3/estimacion-y-intervalos.md", "ud4/distribuciones-derivadas-normal.md"]
---

## Objetivo

âœ¨ Comprender quÃ© es un estimador puntual, analizar sus propiedades deseables (insesgadez, eficiencia, consistencia) y usar el error cuadrÃ¡tico medio (ECM) para seleccionar el mejor estimador en cada situaciÃ³n.

## Idea Clave ðŸ’¡

**Un estimador puntual es una funciÃ³n de la muestra que produce un Ãºnico valor para aproximar un parÃ¡metro poblacional desconocido.** La clave es elegir el estimador con mejores propiedades: insesgadez (no tiene error sistemÃ¡tico), eficiencia (menor varianza) y consistencia (mejora con mÃ¡s datos).

### Ãrbol de DecisiÃ³n: Elegir Estimador

```mermaid
graph TD
    A["Â¿CuÃ¡l estimador usar?"] -->|Â¿ParÃ¡metro es media?| B["Usa media muestral XÌ„"]
    A -->|Â¿ParÃ¡metro es varianza?| C["Usa SÂ²/n-1"]
    A -->|Â¿ParÃ¡metro es proporciÃ³n?| D["Usa pÌ‚"]

    B --> E["Siempre insesgado"]
    C --> F["Insesgado si Normal"]
    D --> G["Insesgado"]

    E --> H["Varianza = ÏƒÂ²/n"]
    F --> I["ECM depende de sesgo"]
    G --> J["Varianza = p(1-p)/n"]
```

---

## ðŸ“Œ Definiciones BÃ¡sicas

### ParÃ¡metro vs Estimador vs EstimaciÃ³n

| Concepto        | DefiniciÃ³n                                  | Ejemplo             |
| :-------------- | :------------------------------------------ | :------------------ |
| **ParÃ¡metro Î¸** | Valor fijo pero desconocido en poblaciÃ³n    | Î¼ (media verdadera) |
| **Estimador Î¸Ì‚** | FunciÃ³n de los datos (variable aleatoria)   | XÌ„ = (1/n)Î£X_i       |
| **EstimaciÃ³n**  | Valor numÃ©rico concreto tras observar datos | XÌ„ = 52.3            |

**Nota:** Estimador es funciÃ³n (cambia entre muestras); estimaciÃ³n es nÃºmero (fijo para datos concretos).

???+ example "Control de calidad"

    **ParÃ¡metro:** DiÃ¡metro medio verdadero Î¼ de tuercas

    **Estimador:** XÌ„ = (1/n)Î£X_i (varÃ­a segÃºn muestra)

    **EstimaciÃ³n:** XÌ„ = 10.05 mm (resultado de esta muestra)

---

## ðŸ“Š Propiedades Deseables de Estimadores

### 1. Insesgadez

Un estimador es **insesgado** si $E[\hat{\theta}] = \theta$ (no tiene error sistemÃ¡tico).

$$\text{Sesgo}(\hat{\theta}) = E[\hat{\theta}] - \theta$$

| Propiedad     | InterpretaciÃ³n                        |
| :------------ | :------------------------------------ |
| **Sesgo = 0** | Estimador centrado en verdadero valor |
| **Sesgo > 0** | Tiende a sobrestimar                  |
| **Sesgo < 0** | Tiende a subestimar                   |

???+ example "Media vs mediana"

    Para distribuciÃ³n Normal: XÌ„ es insesgada (E[XÌ„]=Î¼), mediana es insesgada (E[Md]=Î¼), ambas vÃ¡lidas.

    Para distribuciÃ³n sesgada: XÌ„ es insesgada, pero mediana puede ser sesgada.

### 2. Eficiencia

Un estimador es **mÃ¡s eficiente** si tiene **menor varianza** entre estimadores insesgados de la misma clase.

$$\text{Var}(\hat{\theta}) = E[\hat{\theta}^2] - (E[\hat{\theta}])^2$$

???+ example "Comparar varianzas"

    - Media muestral: Var(XÌ„) = ÏƒÂ²/n
    - Mediana muestral: Var(Md) â‰ˆ (Ï€/2)(ÏƒÂ²/n) â‰ˆ 1.57(ÏƒÂ²/n)

    XÌ„ es mÃ¡s eficiente (menor varianza).

### 3. Consistencia

Un estimador es **consistente** si converge al parÃ¡metro verdadero cuando $n \to \infty$:

$$\hat{\theta}_n \xrightarrow{P} \theta \quad \text{cuando} \quad n \to \infty$$

**Regla prÃ¡ctica:** Si Var($\hat{\theta}$) â†’ 0 y sesgo â†’ 0 cuando n â†’ âˆž, el estimador es consistente.

???+ example "Media muestral"

    $$\text{Var}(\bar{X}) = \frac{\sigma^2}{n} \to 0 \quad \text{cuando} \quad n \to \infty$$

    XÌ„ es consistente para Î¼.

### 4. Error CuadrÃ¡tico Medio (ECM)

El **ECM** combina varianza y sesgo, permitiendo comparar estimadores aunque uno sea sesgado:

$$\text{ECM}(\hat{\theta}) = \text{Var}(\hat{\theta}) + [\text{Sesgo}(\hat{\theta})]^2$$

**InterpretaciÃ³n:** Mide desviaciÃ³n promedio cuadrada del estimador respecto al parÃ¡metro verdadero.

???+ example "Comparar ECM"

    Estimador A: insesgado, Var = 10, Sesgo = 0
    - ECM(A) = 10 + 0Â² = 10

    Estimador B: sesgado, Var = 2, Sesgo = 2
    - ECM(B) = 2 + 2Â² = 6

    B es mejor globalmente a pesar de ser sesgado.

---

## ðŸ“Š Estimadores Comunes y sus Propiedades

### Media Muestral

$$\bar{X} = \frac{1}{n}\sum_{i=1}^n X_i$$

| Propiedad              | Valor                      |
| :--------------------- | :------------------------- |
| **ParÃ¡metro estimado** | Î¼ (media poblacional)      |
| **Insesgadez**         | âœ… E[XÌ„] = Î¼                |
| **Varianza**           | Var(XÌ„) = ÏƒÂ²/n              |
| **ECM**                | ÏƒÂ²/n                       |
| **Consistencia**       | âœ… Var(XÌ„) â†’ 0 cuando n â†’ âˆž |

???+ example "CÃ¡lculo de ECM"

    Datos: X_i ~ N(100, 15Â²), n = 25

    $$\text{ECM}(\bar{X}) = \frac{15^2}{25} = \frac{225}{25} = 9$$

    DesviaciÃ³n estÃ¡ndar: âˆš9 = 3 (XÌ„ tÃ­picamente 100 Â± 3)

### Varianza Muestral

$$S^2 = \frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2$$

| Propiedad              | Valor                                  |
| :--------------------- | :------------------------------------- |
| **ParÃ¡metro estimado** | ÏƒÂ² (varianza poblacional)              |
| **Insesgadez**         | âœ… E[SÂ²] = ÏƒÂ² (si poblaciÃ³n Normal)    |
| **Nota importante**    | Si usas 1/n: sesgado, pero consistente |
| **Consistencia**       | âœ… Converge a ÏƒÂ² cuando n â†’ âˆž          |

???+ example "Sesgo en divisor"

    Usar 1/n: $E[S^2_{n}] = \frac{n-1}{n}\sigma^2$ (sesgo = -ÏƒÂ²/n)

    Usar 1/(n-1): E[SÂ²] = ÏƒÂ² (insesgado)

### ProporciÃ³n Muestral

$$\hat{p} = \frac{1}{n}\sum_{i=1}^n X_i, \quad X_i \sim \text{Ber}(p)$$

| Propiedad              | Valor                     |
| :--------------------- | :------------------------ |
| **ParÃ¡metro estimado** | p (probabilidad de Ã©xito) |
| **Insesgadez**         | âœ… E[pÌ‚] = p               |
| **Varianza**           | Var(pÌ‚) = p(1-p)/n         |
| **ECM**                | p(1-p)/n                  |
| **Consistencia**       | âœ… Convergente por LGN    |

???+ example "Encuesta electoral"

    Muestra: n=400, pÌ‚=0.45 (45% votarÃ­a sÃ­)

    $$\text{Var}(\hat{p}) = \frac{0.45 \times 0.55}{400} = 0.000619$$

    $$\text{DE}(\hat{p}) = \sqrt{0.000619} \approx 0.0249 \approx 2.5\%$$

---

## âš ï¸ Trampas Comunes

**Trampa 1: Confundir estimador con estimaciÃ³n**

- âŒ Incorrecto: "El estimador de Î¼ es 52.5" (52.5 es estimaciÃ³n, no funciÃ³n)
- âœ… Correcto: "El estimador es XÌ„; para estos datos, la estimaciÃ³n es 52.5"

**Trampa 2: Usar 1/n en lugar de 1/(n-1) para varianza**

- âŒ Incorrecto: $S^2 = \frac{1}{n}\sum(X_i-\bar{X})^2$ (sesgado)
- âœ… Correcto: $S^2 = \frac{1}{n-1}\sum(X_i-\bar{X})^2$ (insesgado)

**Trampa 3: Asumir insesgadez implica eficiencia**

- âŒ Incorrecto: Todos los estimadores insesgados tienen la misma varianza
- âœ… Correcto: Comparar varianzas; elegir de menor Var entre insesgados

**Trampa 4: Confundir Var(X) con Var(XÌ„)**

- âŒ Incorrecto: Var(XÌ„) = ÏƒÂ² (varianza de dato individual)
- âœ… Correcto: Var(XÌ„) = ÏƒÂ²/n (varianza de promedio)

**Trampa 5: Ignorar sesgo en comparativas**

- âŒ Incorrecto: Elegir estimador solo por insesgadez
- âœ… Correcto: Comparar ECM (combina varianza y sesgo)

---

## ðŸ’¡ Checklist: Analizar un Estimador

!!! tip "Paso a Paso"

    1. **Identifica parÃ¡metro:** Â¿QuÃ© poblaciÃ³n parameter estimar? (Î¼, ÏƒÂ², p, ...)
    2. **PropÃ³n estimador:** Â¿QuÃ© funciÃ³n de datos usar?
    3. **Calcula E[Î¸Ì‚]:** Usando linealidad de esperanza
    4. **Calcula Var(Î¸Ì‚):** Usando propiedades de varianza
    5. **Sesgo:** Sesgo = E[Î¸Ì‚] - Î¸
    6. **ECM:** ECM = Var + SesgoÂ²
    7. **Consistencia:** Â¿Var â†’ 0 y Sesgo â†’ 0 cuando n â†’ âˆž?
    8. **Compara:** Si hay alternativas, elige menor ECM
    9. **Reporta:** Estimador elegido, propiedades, ECM

---

## ðŸ“š Ejercicios RÃ¡pidos

Estimador propuesto: $\tilde{\mu}=\frac{1}{n-1}\sum_{i=1}^n X_i$. Calcula sesgo para E[X] = Î¼.

???+ example "Ejercicio 1 â€” Sesgo de estimador"

    $$E[\tilde{\mu}] = E\left[\frac{1}{n-1}\sum X_i\right] = \frac{n}{n-1}\mu$$

    $$\text{Sesgo} = E[\tilde{\mu}] - \mu = \frac{n}{n-1}\mu - \mu = \frac{\mu}{n-1}$$

    Para n grande, sesgo â†’ 0 (consistente).

Estimador A: insesgado, Var(A) = 4/n. Estimador B: Var(B) = 1/n, Sesgo(B) = 1/n. Para n=25, Â¿cuÃ¡l tiene menor ECM?

???+ example "Ejercicio 2 â€” Comparar ECM"

    $$\text{ECM}(A) = \frac{4}{25} + 0^2 = 0.16$$

    $$\text{ECM}(B) = \frac{1}{25} + \left(\frac{1}{25}\right)^2 = 0.04 + 0.0016 = 0.0416$$

    B gana (menor ECM) a pesar de ser sesgado.

PoblaciÃ³n: X ~ N(70, 12Â²), n=36. Â¿CuÃ¡l es Var(XÌ„) y DE(XÌ„)?

???+ example "Ejercicio 3 â€” Varianza de media muestral"

    $$\text{Var}(\bar{X}) = \frac{\sigma^2}{n} = \frac{144}{36} = 4$$

    $$\text{DE}(\bar{X}) = \sqrt{4} = 2$$

    InterpretaciÃ³n: Media muestral tÃ­picamente Â±2 unidades de media verdadera.

## ðŸ“– Enlaces Relacionados

- **UD3:** [EstimaciÃ³n e Intervalos](../../ud3/estimacion-y-intervalos.md) â€” IntroducciÃ³n
- **UD5:** [MÃ©todos de EstimaciÃ³n](./metodos-estimacion.md) â€” MV, momentos
- **UD5:** [Intervalos de Confianza](./intervalos-confianza.md) â€” EstimaciÃ³n por intervalos
- **UD5:** [Contrastes de HipÃ³tesis](./contrastes-hipotesis.md) â€” Tests
