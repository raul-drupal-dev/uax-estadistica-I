title: "Limpieza de datos"
slug: "ud1-limpieza-datos"
date: "2026-01-14"
authors: ["Profesor UAX"]
tags: ["ud1", "limpieza", "datos", "eda", "calidad", "outliers"]
difficulty: "intro"
type: "definicion"
prerequisitos: ["ud1-tipos-datos", "ud1-representacion-visual"]

---

## Objetivo

âœ¨ Dominar tÃ©cnicas para **detectar y corregir problemas comunes** en datos reales (faltantes, duplicados, errores, outliers) antes del anÃ¡lisis, garantizando conclusiones vÃ¡lidas.

## Idea Clave ğŸ’¡

**"Garbage In, Garbage Out"** â€” Si los datos estÃ¡n sucios, ningÃºn anÃ¡lisis riguroso puede salvarte. El 80% del trabajo en anÃ¡lisis real es **limpieza de datos**. Aprende a hacerlo bien y evitarÃ¡s horas de frustraciÃ³n.

---

## Â¿Por QuÃ© Limpiar Datos?

**Problema:** Los datos reales vienen con imperfecciones:

- Valores faltantes (NA, NaN, espacios en blanco)
- Duplicados accidentales
- Errores de formato/tipeo
- Valores fuera de rango lÃ³gico
- Caracteres especiales mal codificados

**Consecuencia:** AnÃ¡lisis con datos sucios â†’ Conclusiones engaÃ±osas

???+ example "Ejemplo: Media Distorsionada"

    Dataset: Edades [23, 25, 999, 30, 22]

    âŒ INCORRECTO (sin limpiar):
    $$\bar{x} = \frac{23+25+999+30+22}{5} = \frac{1099}{5} = 219.8 \text{ aÃ±os}$$

    âœ… CORRECTO (tras limpiar, 999 â†’ NA â†’ imputar mediana = 25):
    $$\bar{x} = \frac{23+25+25+30+22}{5} = \frac{125}{5} = 25 \text{ aÃ±os}$$

---

## Problemas Comunes y Soluciones

### 1. Valores Faltantes (NA)

**Patrones:** Pueden ser **aleatorios (MCAR)**, **dependientes de otros datos (MAR)**, o **no aleatorios (MNAR)**.

**DetecciÃ³n:**

- Contar NAs por variable
- Visualizar patrÃ³n (Â¿estÃ¡n concentrados?)
- Investigar causa (error de captura vs intencional)

**Estrategias de Tratamiento:**

| **Estrategia**            | **CuÃ¡ndo Usar**      | **Ventajas**      | **Desventajas**            |
| :------------------------ | :------------------- | :---------------- | :------------------------- |
| **Eliminar fila**         | Muy pocos NA (<5%)   | Simple            | Pierdes informaciÃ³n        |
| **Imputar media/mediana** | Cuantitativos, MCAR  | RÃ¡pido            | Reduce varianza            |
| **Imputar moda**          | CategÃ³ricos          | Intuitivo         | Artificial                 |
| **RegresiÃ³n/k-NN**        | Relaciones complejas | Preserva varianza | MÃ¡s complejo               |
| **ImputaciÃ³n mÃºltiple**   | AnÃ¡lisis formal      | Riguroso          | Computacionalmente costoso |

???+ example "Ejemplo: ImputaciÃ³n de Peso"

    Dataset: Pesos [70kg, 75kg, NA, 80kg, 72kg]

    OpciÃ³n 1 - Eliminar: [70, 75, 80, 72] â†’ Pierdo 1/5 de datos

    OpciÃ³n 2 - Media: [70, 75, **74.25**, 80, 72] â†’ Imputar promedio

    OpciÃ³n 3 - Mediana: [70, 75, **72**, 80, 72] â†’ Imputar valor central

    **RecomendaciÃ³n:** Mediana (mÃ¡s robusta con outliers)

---

### 2. Duplicados

**DetecciÃ³n:**

- Buscar filas idÃ©nticas (todas las columnas iguales)
- Buscar duplicados en ID (imposible en ID Ãºnico)
- Agrupar por variables clave y contar

**Tratamiento:**

!!! tip "Manejo de Duplicados"

    1. **Nunca eliminar sin revisar** â€” PodrÃ­a ser error de captura o dato legÃ­timo
    2. **Documentar criterio** â€” Â¿Guardas primera ocurrencia o la mÃ¡s completa?
    3. **Crear flag** â€” Marcar registros duplicados en columna `is_duplicate`
    4. **Auditar** â€” Revisar muestra de duplicados antes de eliminar

???+ example "Ejemplo: Encuesta con ReenvÃ­o Accidental"

    Datos recibidos:
    ```
    id,nombre,email,respuesta
    001,Juan,juan@mail,SÃ­
    002,MarÃ­a,maria@mail,No
    001,Juan,juan@mail,SÃ­  â† DUPLICADO (reenvÃ­o accidental)
    003,Pedro,pedro@mail,SÃ­
    ```

    **SoluciÃ³n:** Mantener primer registro (001 Ãºnico), marcar segundo como duplicado, documentar

---

### 3. Errores de Formato/Consistencia

**Problemas tÃ­picos:**

- Tipos mezclados: "10" vs 10 vs "diez"
- Unidades inconsistentes: "170cm" vs "1.7m"
- Fechas variadas: "01/02/2024" vs "2024-02-01" vs "1 febrero 2024"
- Encoding: caracteres especiales (â‚¬, Ã±, Â°) corruptos

**Soluciones:**

!!! warning "ValidaciÃ³n de Formato"

    1. **Normaliza tipos:** Todo numÃ©rico en nÃºmero, texto en string
    2. **Estandariza unidades:** cm siempre, o m siempre (no mezclar)
    3. **Fechas ISO:** YYYY-MM-DD es estÃ¡ndar internacional
    4. **Encoding UTF-8:** Asegura caracteres especiales correctos

???+ example "Ejemplo: Temperatura"

    âŒ Inconsistente:
    ```
    temperatura
    20 Â°C
    68Â°F
    293K
    "veinte grados"
    ```

    âœ… Normalizado (todo Celsius):
    ```
    temperatura_celsius
    20.0
    20.0  (convertido de 68Â°F)
    19.85 (convertido de 293K)
    NA    (no numÃ©rico, marcar como NA)
    ```

---

### 4. Valores AtÃ­picos (Outliers)

**DefiniciÃ³n:** Valores **muy alejados** de la distribuciÃ³n normal â€” pueden ser errores o fenÃ³menos reales.

**DetecciÃ³n con IQR (Rango Intercuartil):**

$$\text{IQR} = Q_3 - Q_1$$

Outliers: Valores fuera de $[Q_1 - 1.5 \times \text{IQR}, Q_3 + 1.5 \times \text{IQR}]$

**DetecciÃ³n con Z-score:**

$$z = \frac{x - \bar{x}}{s}$$

Outliers: |z| > 3 (aproximadamente)

**Â¿QuÃ© hacer con outliers?**

| **Paso**          | **AcciÃ³n**                                            |
| :---------------- | :---------------------------------------------------- |
| 1ï¸âƒ£ **Investigar** | Â¿Es error o fenÃ³meno real?                            |
| 2ï¸âƒ£ **Documentar** | Registra quÃ© y por quÃ©                                |
| 3ï¸âƒ£ **Decidir**    | Eliminar, corregir o mantener + usar medidas robustas |
| 4ï¸âƒ£ **Reportar**   | Siempre menciona outliers en anÃ¡lisis                 |

???+ example "Ejemplo: Salarios con CEO"

    Datos: [30k, 35k, 40k, 42k, 1000k]

    Media (con outlier): 229.4k â† Distorsionada âŒ

    Mediana (robusto): 40k â† Representa bien âœ…

    **DecisiÃ³n:** Mantener 1000k porque es CEO real, pero usar mediana y documentar

---

## Flujo Completo de Limpieza

```mermaid
graph TD
    A["1ï¸âƒ£ INSPECCIÃ“N<br/>Dimensiones, tipos, NA"] --> B["2ï¸âƒ£ RESUMEN<br/>Freq, valores Ãºnicos, stats"]
    B --> C["3ï¸âƒ£ VISUALIZACIÃ“N<br/>Histogramas, boxplots, barras"]
    C --> D{"Â¿Problemas<br/>detectados?"}
    D -->|SÃ| E["4ï¸âƒ£ APLICAR REGLAS<br/>Faltantes, duplicados, formato, outliers"]
    D -->|NO| F["âœ… DATOS LIMPIOS"]
    E --> G["5ï¸âƒ£ VALIDACIÃ“N<br/>Stats antes/despuÃ©s, spot-check"]
    G --> H{"Â¿Cambios<br/>razonables?"}
    H -->|SÃ| F
    H -->|NO| E

    style A fill:#e3f2fd
    style F fill:#c8e6c9
```

---

## Checklist de Limpieza

!!! tip "Pasos Recomendados"

    - [ ] Cargar dataset â†’ Revisar dimensiones (filas, columnas)
    - [ ] Tipos: Â¿Cada variable tiene tipo correcto?
    - [ ] Valores faltantes: Â¿CuÃ¡ntos NA por variable? Â¿PatrÃ³n?
    - [ ] Duplicados: Â¿Existen filas idÃ©nticas? Â¿Duplicados en ID?
    - [ ] Formatos: Â¿Fechas ISO? Â¿Unidades consistentes?
    - [ ] Valores fuera de rango: Â¿Edad = 999? Â¿Nota = 150?
    - [ ] Outliers: Â¿Boxplot muestra valores sospechosos?
    - [ ] Documentar: Registro de cambios, quiÃ©n, cuÃ¡ndo, por quÃ©
    - [ ] Validar: Comparar estadÃ­sticas antes/despuÃ©s
    - [ ] Backup: Guardar dataset original sin modificar

---

## Buenas PrÃ¡cticas

!!! warning "Nunca Modificar Original"

    Siempre trabaja con **copias**. MantÃ©n el dataset original intacto para auditorÃ­a y reproducibilidad.

!!! note "DocumentaciÃ³n Completa"

    Crea un **registro de cambios**:

    ```
    Cambio: Sustituir edad=999 por NA
    Autor: Prof. GarcÃ­a
    Fecha: 2024-01-14
    JustificaciÃ³n: 999 es cÃ³digo de error de captura
    Variables afectadas: edad (1 fila)
    ```

!!! tip "Script Reproducible"

    Escribe tu limpieza como script (Python/R) para:
    - Reproducibilidad
    - AuditorÃ­a
    - Aplicar a nuevos datos

---

## ğŸ“– Enlaces Relacionados

- [RepresentaciÃ³n visual](./representacion-visual.md) â€” Visualizar problemas
- [Tipos de datos](./tipos-datos.md) â€” Validar tipos
- [ObservaciÃ³n y registro](./observacion-registro.md) â€” Prevenir problemas en origen
