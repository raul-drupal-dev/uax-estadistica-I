---
title: "Esperanza Matem√°tica y Varianza"
slug: "ud3-esperanza-varianza"
tags: ["esperanza", "varianza", "E[X]", "Var(X)", "momentos"]
difficulty: "Intermedio"
prerequisitos: ["ud3-funciones-distribucion", "ud1-medidas-tendencia-dispersion"]
---

# üé≤ Esperanza Matem√°tica y Varianza

## üìç Esperanza Matem√°tica (E[X])

### Definici√≥n

La **esperanza matem√°tica** (tambi√©n llamada _valor esperado_ o _media_) representa el **valor promedio** de una variable aleatoria en un n√∫mero infinito de realizaciones:

$$E[X] = \mu_X$$

### C√°lculo: Variable Discreta

Para una VA discreta $X$ con PMF $p_X(x)$:

$$E[X] = \sum_{x} x \cdot p_X(x)$$

Se multiplica cada valor posible por su probabilidad y se suman.

### C√°lculo: Variable Continua

Para una VA continua $X$ con PDF $f_X(x)$:

$$E[X] = \int_{-\infty}^{\infty} x \cdot f_X(x) \, dx$$

Integral en lugar de suma.

### Ejemplo 1: Juego de Dados

Lanzar un dado equilibrado, ganar euros seg√∫n el resultado:

- Si sale 1: ganas ‚Ç¨1
- Si sale 2: ganas ‚Ç¨2
- ...
- Si sale 6: ganas ‚Ç¨6

$$E[X] = 1 \cdot \frac{1}{6} + 2 \cdot \frac{1}{6} + 3 \cdot \frac{1}{6} + 4 \cdot \frac{1}{6} + 5 \cdot \frac{1}{6} + 6 \cdot \frac{1}{6}$$

$$= \frac{1 + 2 + 3 + 4 + 5 + 6}{6} = \frac{21}{6} = 3.5 \text{ euros}$$

**Interpretaci√≥n:** A largo plazo, ganas en promedio ‚Ç¨3.50 por tirada.

### Ejemplo 2: Apuestas Justas

Una apuesta es **justa** si $E[\text{Ganancia}] = 0$.

- Probabilidad de ganar ‚Ç¨10: 0.4
- Probabilidad de perder ‚Ç¨6.67: 0.6

$$E[X] = 10 \cdot 0.4 + (-6.67) \cdot 0.6 = 4 - 4 = 0$$ ‚úì Justa

---

## üîß Propiedades de la Esperanza

La esperanza tiene propiedades algebraicas muy √∫tiles:

### 1. Linealidad

$$E[aX + b] = aE[X] + b$$

Donde $a$ y $b$ son constantes.

**Ejemplo:**

- Original: $X$ = salario en miles de euros, $E[X] = 50$
- Convertir a euros anuales: $Y = 12 \cdot X$ (12 meses)
- $E[Y] = 12 \cdot 50 = 600$ (‚Ç¨ miles anuales)

### 2. Suma de Variables

$$E[X + Y] = E[X] + E[Y]$$

**No requiere independencia.**

**Ejemplo:**

- Cartera con 2 acciones: $X$ = rendimiento acci√≥n A, $Y$ = rendimiento acci√≥n B
- Rendimiento esperado total: $E[X + Y] = E[X] + E[Y]$

### 3. Linealidad Generalizada

$$E[a_1X_1 + a_2X_2 + \ldots + a_nX_n] = a_1E[X_1] + a_2E[X_2] + \ldots + a_nE[X_n]$$

**Crucial en redes neuronales:** Combinaciones lineales de capas.

### 4. Esperanza de Constante

$$E[c] = c$$

Una constante es su propio valor esperado.

---

## üìä Varianza (Var(X))

### Definici√≥n

La **varianza** mide la **dispersi√≥n** o **variabilidad** de una VA respecto a su media:

$$\text{Var}(X) = E[(X - E[X])^2] = E[(X - \mu)^2]$$

Promedio de las desviaciones cuadradas.

### F√≥rmula Computacional

M√°s f√°cil de calcular:

$$\text{Var}(X) = E[X^2] - (E[X])^2$$

Donde:

- $E[X^2] = \sum_x x^2 p_X(x)$ (discreta) o $\int x^2 f_X(x)dx$ (continua)
- $(E[X])^2 = \mu^2$

### Ejemplo: Variabilidad de Servidores

**Servidor A:** Tiempo respuesta 100ms siempre

- $E[X_A] = 100$
- $\text{Var}(X_A) = 0$ (sin variabilidad)

**Servidor B:** Tiempo respuesta 50ms o 150ms, cada uno 50%

- $E[X_B] = 50 \cdot 0.5 + 150 \cdot 0.5 = 100$
- $E[X_B^2] = 50^2 \cdot 0.5 + 150^2 \cdot 0.5 = 1250 + 11250 = 12500$
- $\text{Var}(X_B) = 12500 - 100^2 = 12500 - 10000 = 2500$

**Conclusi√≥n:** Ambos tienen media 100ms, pero B es mucho m√°s variable.

---

## üìè Desviaci√≥n T√≠pica (œÉ)

### Definici√≥n

La **desviaci√≥n t√≠pica** (o _est√°ndar_) es la ra√≠z cuadrada de la varianza:

$$\sigma_X = \sqrt{\text{Var}(X)}$$

**Ventaja:** Tiene las mismas unidades que $X$ (a diferencia de varianza, que est√° al cuadrado).

### Ejemplo Continuo

Para $X \sim N(\mu = 100, \sigma = 15)$ (normal):

- Media: 100ms
- Desviaci√≥n t√≠pica: 15ms
- Interpretaci√≥n: t√≠picamente var√≠a ¬±15ms respecto a la media

---

## üîß Propiedades de la Varianza

### 1. Varianza de Constante

$$\text{Var}(c) = 0$$

Las constantes no var√≠an.

### 2. Escalado

$$\text{Var}(aX) = a^2 \text{Var}(X)$$

‚ö†Ô∏è Nota el **cuadrado** en $a^2$.

**Ejemplo:** Si $X$ est√° en euros y queremos en c√©ntimos:

- $Y = 100X$ (de euros a c√©ntimos)
- $\text{Var}(Y) = 100^2 \cdot \text{Var}(X) = 10000 \cdot \text{Var}(X)$

### 3. Traslaci√≥nno afecta varianza

$$\text{Var}(X + b) = \text{Var}(X)$$

Sumar constante no cambia dispersi√≥n, solo desplaza.

### 4. Suma de Variables Independientes

Si $X$ e $Y$ son **independientes**:

$$\text{Var}(X + Y) = \text{Var}(X) + \text{Var}(Y)$$

‚ö†Ô∏è **Si NO son independientes**, esto no es v√°lido.

**Ejemplo:** Cartera de 2 acciones

- $\text{Var}(X) = 0.04$ (stock A)
- $\text{Var}(Y) = 0.09$ (stock B)
- Si son independientes: $\text{Var}(X + Y) = 0.04 + 0.09 = 0.13$
- Si est√°n correlacionadas positivamente (suben juntas): varianza > 0.13

---

## üìà Tabla de Formulas Clave

| Concepto            | Discreta                            | Continua                            |
| ------------------- | ----------------------------------- | ----------------------------------- |
| **Esperanza**       | $E[X] = \sum x \cdot p_X(x)$        | $E[X] = \int x \cdot f_X(x)dx$      |
| **Segundo momento** | $E[X^2] = \sum x^2 \cdot p_X(x)$    | $E[X^2] = \int x^2 \cdot f_X(x)dx$  |
| **Varianza**        | $\text{Var}(X) = E[X^2] - (E[X])^2$ | $\text{Var}(X) = E[X^2] - (E[X])^2$ |
| **Desv. T√≠pica**    | $\sigma = \sqrt{\text{Var}(X)}$     | $\sigma = \sqrt{\text{Var}(X)}$     |

---

## üéØ Momentos Superiores

### Sesgo (Skewness)

Mide **asimetr√≠a** de la distribuci√≥n:

$$\text{Skewness} = E\left[\left(\frac{X - \mu}{\sigma}\right)^3\right]$$

- $= 0$: Sim√©trica (distribuci√≥n normal)
- $> 0$: Cola larga a la derecha (positivo sesgada)
- $< 0$: Cola larga a la izquierda (negativo sesgada)

### Curtosis (Kurtosis)

Mide **colas pesadas** (qu√© tan extremos son los valores):

$$\text{Kurtosis} = E\left[\left(\frac{X - \mu}{\sigma}\right)^4\right] - 3$$

- $= 0$: Normal (mesoc√∫rtica)
- $> 0$: Colas pesadas (leptoc√∫rtica) - m√°s valores extremos
- $< 0$: Colas ligeras (platic√∫rtica) - menos valores extremos

---

## üöÄ Aplicaciones en IA/ML

### 1. Inicializaci√≥n de Pesos

```python
# Xavier initialization: E[W] = 0, Var(W) = 2/(n_in + n_out)
W = np.random.normal(loc=0, scale=np.sqrt(2/(n_in + n_out)))
```

Mantiene varianza manejable para que se√±ales no exploten.

### 2. Batch Normalization

Normaliza capas para tener $E[X] = 0$ y $\text{Var}(X) = 1$:

$$\hat{X} = \frac{X - E[X]}{\sqrt{\text{Var}(X) + \epsilon}}$$

### 3. Incertidumbre en Predicciones

Modelos bayesianos predicen tanto media como varianza:

$$\hat{y} = \mu(x) \quad \text{con} \quad \sigma^2(x)$$

Permite saber cu√°ndo el modelo es "inseguro".

### 4. Dropout como Regularizaci√≥n

Apagar neuronas aleatoriamente aumenta varianza del entrenamiento pero reduce sobreajuste:

$$\text{Var(Entrenamiento)} \uparrow \Rightarrow \text{Sobreajuste} \downarrow$$

---

## ‚úÖ Resumen de Conceptos

| T√©rmino             | S√≠mbolo                   | Interpretaci√≥n                  |
| ------------------- | ------------------------- | ------------------------------- |
| **Esperanza**       | $E[X], \mu$               | Valor promedio                  |
| **Varianza**        | $\text{Var}(X), \sigma^2$ | Dispersi√≥n respecto a media     |
| **Desv. T√≠pica**    | $\sigma, SD$              | Varianza en unidades originales |
| **Segundo momento** | $E[X^2]$                  | Promedio de cuadrados           |
| **Sesgo**           | Skewness                  | Asimetr√≠a                       |
| **Curtosis**        | Kurtosis                  | Extremidad de colas             |

---

## üéì Ejercicio Pr√°ctico

Una red neuronal predice precio de casas ($X$ en miles de euros):

**Datos de validaci√≥n:**

- Media predicha: $E[X] = 300$
- Desv. T√≠pica: $\sigma = 50$

**Preguntas:**

1. ¬øCu√°l es $\text{Var}(X)$?
2. Si transformamos a euros: $Y = 1000 \cdot X$, ¬øcu√°l es $\sigma_Y$?
3. Si la distribuci√≥n es normal $N(300, 50)$, ¬øaproximadamente qu√© porcentaje de predicciones caen en $[250, 350]$?

??? example "Soluciones"

    1. **$\text{Var}(X) = \sigma^2 = 50^2 = 2500$** (miles¬≤ de euros¬≤)

    2. **$\sigma_Y = 1000 \cdot \sigma_X = 1000 \cdot 50 = 50,000$** euros
       - Aplicamos propiedad: $\text{SD}(aX) = a \cdot \text{SD}(X)$

    3. **~95%**
       - $[250, 350] = [300 - 50, 300 + 50] = [\mu - \sigma, \mu + \sigma]$
       - En normal, 1œÉ abarca ~68%, 2œÉ abarca ~95%
       - Este intervalo es $[300 - 1\sigma, 300 + 1\sigma]$ ‚Üí ~68%
       - (Correcci√≥n: el intervalo es ¬±50 = 1œÉ ‚Üí ~68%, no 95%)
