title: "RegresiÃ³n lineal simple: Modelar relaciones"
slug: "ud3-regresion-simple"
date: "2026-01-14"
authors: ["Profesor UAX"]
tags: ["ud3", "regresion", "lineal", "mco", "ajuste"]
difficulty: "intermedio"
type: "definicion"
prerequisitos: ["ud3-pruebas-hipotesis", "ud2-distribuciones-continuas"]

---

## Objetivo

âœ¨ Modelar relaciones lineales entre variables, estimar parÃ¡metros por MÃ­nimos Cuadrados Ordinarios (MCO) y evaluar la calidad del ajuste.

## Idea Clave ğŸ’¡

**La regresiÃ³n responde: "Â¿CÃ³mo predice X a Y?"** Ajustamos una lÃ­nea a travÃ©s de los datos para entender y pronosticar la relaciÃ³n. El ajuste nunca es perfecto (hay residuos/errores).

---

## Modelo de RegresiÃ³n Lineal Simple

### FormulaciÃ³n

$$Y = \beta_0 + \beta_1 X + \varepsilon$$

Donde:

- **Y:** variable dependiente (respuesta)
- **X:** variable independiente (predictor)
- **Î²â‚€:** ordenada en el origen (intersecciÃ³n)
- **Î²â‚:** pendiente (cambio en Y por unidad en X)
- **Îµ:** tÃ©rmino de error (variabilidad no explicada)

**Supuestos:**

1. âœ… Linealidad: relaciÃ³n verdadera es lineal
2. âœ… Independencia: observaciones independientes
3. âœ… Homocedasticidad: Var(Îµ) es constante
4. âœ… Normalidad: Îµ ~ N(0, ÏƒÂ²)

### InterpretaciÃ³n de ParÃ¡metros

- **Î²â‚:** Por cada aumento unitario en X, Y aumenta en promedio Î²â‚ unidades
- **Î²â‚€:** Valor predicho de Y cuando X = 0 (a veces sin interpretaciÃ³n prÃ¡ctica)

???+ example "Ejemplo Conceptual: Publicidad vs Ventas"

    Modelo: Ventas = 10 + 5Â·Publicidad + Îµ

    - Î²â‚€ = 10: sin gastos en publicidad, se predicen 10 unidades de venta base
    - Î²â‚ = 5: cada euro invertido en publicidad genera 5 euros de ventas en promedio

---

## EstimaciÃ³n por MÃ­nimos Cuadrados Ordinarios (MCO)

### FormulaciÃ³n

Queremos minimizar la suma de cuadrados de residuos:

$$\text{SSE} = \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 = \sum_{i=1}^{n} (y_i - \beta_0 - \beta_1 x_i)^2$$

Las soluciones MCO son:

$$\hat{\beta}_1 = \frac{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}{\sum_{i=1}^{n} (x_i - \bar{x})^2} = \frac{\text{Cov}(X,Y)}{\text{Var}(X)}$$

$$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1 \bar{x}$$

**InterpretaciÃ³n:** La pendiente es la covarianza escalada por la varianza de X.

???+ example "Ejemplo 1: CÃ¡lculo Manual de MCO"

    Datos:

    | X | Y |
    |:---:|:---:|
    | 1 | 2 |
    | 2 | 3 |
    | 3 | 5 |

    Paso 1: Calcular medias

    $$\bar{x} = \frac{1+2+3}{3} = 2$$

    $$\bar{y} = \frac{2+3+5}{3} = \frac{10}{3} \approx 3.333$$

    Paso 2: Calcular numerador y denominador

    $$(x_1-\bar{x})(y_1-\bar{y}) = (1-2)(2-3.333) = (-1)(-1.333) = 1.333$$

    $$(x_2-\bar{x})(y_2-\bar{y}) = (2-2)(3-3.333) = 0$$

    $$(x_3-\bar{x})(y_3-\bar{y}) = (3-2)(5-3.333) = (1)(1.667) = 1.667$$

    Suma numerador = 1.333 + 0 + 1.667 = 3

    $$(x_1-\bar{x})^2 = (1-2)^2 = 1$$

    $$(x_2-\bar{x})^2 = (2-2)^2 = 0$$

    $$(x_3-\bar{x})^2 = (3-2)^2 = 1$$

    Suma denominador = 1 + 0 + 1 = 2

    Paso 3: Calcular estimadores

    $$\hat{\beta}_1 = \frac{3}{2} = 1.5$$
    
    $$\hat{\beta}_0 = 3.333 - 1.5 \times 2 = 3.333 - 3 = 0.333$$

    Modelo estimado: $\hat{Y} = 0.333 + 1.5X$

    **InterpretaciÃ³n:** Por cada unidad que aumenta X, Y aumenta en 1.5 unidades en promedio.

---

## EvaluaciÃ³n del Ajuste

### RÂ² (Coeficiente de DeterminaciÃ³n)

$$R^2 = 1 - \frac{\text{SSE}}{\text{SST}} = \frac{\text{SSR}}{\text{SST}}$$

Donde:

- **SSE:** Suma de cuadrados de residuos (no explicada)
- **SSR:** Suma de cuadrados de regresiÃ³n (explicada)
- **SST:** Suma de cuadrados total

**InterpretaciÃ³n:**

- RÂ² = 1: ajuste perfecto
- RÂ² = 0: el modelo no explica nada
- RÂ² = 0.75: X explica 75% de la variabilidad en Y

**Cautela:** RÂ² alto NO implica causalidad ni que el modelo sea bueno.

???+ example "Ejemplo 2: Calcular RÂ²"

    Continuando el ejemplo anterior:

    Residuos: $\hat{y}_1 = 0.333 + 1.5(1) = 1.833$, residuo = 2 - 1.833 = 0.167

    SSE = 0.167Â² + (3-3)Â² + (5-4.833)Â² â‰ˆ 0.055

    SST = (2-3.333)Â² + (3-3.333)Â² + (5-3.333)Â² = 1.778 + 0.111 + 2.778 = 4.667

    $$R^2 = 1 - \frac{0.055}{4.667} \approx 0.988$$

    Modelo explica ~98.8% de la variabilidad (excelente ajuste).

---

## Tabla Comparativa: Conceptos Clave

| Concepto       | FÃ³rmula                                     | Significado                              |
| :------------- | :------------------------------------------ | :--------------------------------------- |
| **PredicciÃ³n** | $\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x$ | Valor esperado de Y para X dado          |
| **Residuo**    | $e_i = y_i - \hat{y}_i$                     | Diferencia real vs predicho              |
| **SSE**        | $\sum e_i^2$                                | Variabilidad no explicada                |
| **RÂ²**         | $1 - \frac{\text{SSE}}{\text{SST}}$         | ProporciÃ³n de varianza explicada (0 a 1) |
| **Î²â‚**         | Covarianza / Varianza                       | Pendiente; cambio en Y por unidad X      |

---

## Diagrama: RegresiÃ³n Lineal

```mermaid
graph TD
    A["Datos: pares (X,Y)"] --> B["Â¿Existe relaciÃ³n<br/>lineal?"]
    B -->|SÃ| C["Aplicar MCO"]
    B -->|NO| D["Transformar o modelo<br/>no-lineal"]
    C --> E["Obtener Î²â‚€, Î²â‚"]
    E --> F["Calcular predicciones<br/>Å· = Î²â‚€ + Î²â‚x"]
    F --> G["Evaluar ajuste (RÂ²,<br/>residuos)"]
    G --> H["Â¿Buena<br/>calidad?"]
    H -->|SÃ| I["Usar modelo<br/>para inferencia/predicciÃ³n"]
    H -->|NO| J["Revisar supuestos,<br/>outliers"]
```

---

## Inferencia sobre la RegresiÃ³n

### Intervalo de Confianza para Î²â‚

$$\hat{\beta}_1 \pm t_{1-\alpha/2, n-2} \times SE(\hat{\beta}_1)$$

Donde $SE(\hat{\beta}_1) = \frac{s}{\sqrt{\sum(x_i-\bar{x})^2}}$ y s es el error estÃ¡ndar de la regresiÃ³n.

### Contraste sobre Î²â‚

**Hâ‚€:** Î²â‚ = 0 (X no afecta a Y)
**Hâ‚:** Î²â‚ â‰  0 (X sÃ­ afecta a Y)

Si rechazamos Hâ‚€, hay relaciÃ³n estadÃ­sticamente significativa.

---

## âš ï¸ Trampas Comunes

### Trampa 1: CorrelaciÃ³n â‰  Causalidad

âŒ "RÂ² alto significa X causa Y"

âœ… RegresiÃ³n asume X â†’ Y por construcciÃ³n, pero correlaciÃ³n NO implica causalidad. Necesitas razonamiento teÃ³rico.

### Trampa 2: ExtrapolaciÃ³n Peligrosa

âŒ "El modelo con datos 1990-2010 predice bien en 2050"

âœ… Extrapolar fuera del rango de datos es arriesgado. Supuestos pueden no mantenerse.

### Trampa 3: Ignorar Residuos

âŒ "RÂ² = 0.80, modelo listo"

âœ… Visualiza residuos. Busca patrones (no-linealidad, varianza no constante, outliers).

### Trampa 4: MÃºltiples Predictores sin JustificaciÃ³n

âŒ "Agregar Xâ‚‚, Xâ‚ƒ... aumenta RÂ²"

âœ… RÂ² siempre sube con mÃ¡s variables. Usa criterios (AIC, BIC) o justificaciÃ³n teÃ³rica. Riesgo de overfitting.

---

## ğŸ’¡ Checklist: RegresiÃ³n Lineal Simple

!!! tip "Paso a Paso"

    1. [ ] Visualizar scatter plot: Â¿relaciÃ³n lineal?
    2. [ ] Calcular Î²â‚€ y Î²â‚ (MCO)
    3. [ ] Escribir ecuaciÃ³n: Å· = Î²â‚€ + Î²â‚x
    4. [ ] Calcular RÂ² y Ïƒ de residuos
    5. [ ] Visualizar residuos: Â¿aleatorios?
    6. [ ] Contrastar Hâ‚€: Î²â‚ = 0
    7. [ ] Interpretar Î²â‚ en contexto
    8. [ ] Cuidado con extrapolaciÃ³n

---

## ğŸ“ Ejercicios PrÃ¡cticos

!!! tip "PrÃ¡ctica"

    1. Datos: (1,2), (2,4), (3,5), (4,7). RegresiÃ³n Y vs X. Î²â‚€, Î²â‚, RÂ²?
    2. Si RÂ² = 0.64, Â¿quÃ© proporciÃ³n de varianza es NO explicada?
    3. Modelo: Peso = 50 + 2Â·Altura. Interpreta Î²â‚.

---

## ğŸ“– Enlaces Relacionados

- [Pruebas de hipÃ³tesis](./pruebas-hipotesis.md) â€” Contraste sobre Î²â‚
- [Ejercicios UD3](./ejercicios.md) â€” Problemas resueltos paso a paso
